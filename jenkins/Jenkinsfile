pipeline {
    agent any

    parameters {
        string(name: 'BUCKET', defaultValue: 'thesamuraibucket', description: 'S3 bucket name')
        string(name: 'KEY', defaultValue: '', description: 'Exact S3 object key (leave blank to auto-find latest)')
    }

    environment {
        AWS_DEFAULT_REGION = 'eu-central-1'
        TIMESTAMP = "${new Date().format('yyyyMMdd_HHmmss')}"
    }

    stages {

        stage('Checkout Repository') {
            steps {
                script {
                    checkout([$class: 'GitSCM',
                        branches: [[name: '*/main']],
                        userRemoteConfigs: [[url: 'https://github.com/NasriMohamedHedi/terraform-infra.git']]
                    ])
                }
            }
        }

        stage('Find Payload in S3') {
            steps {
                script {
                    env.S3_PAYLOAD_KEY = params.KEY ?: sh(
                        script: "aws s3 ls s3://${params.BUCKET}/ | sort | tail -n 1 | awk '{print \$4}' || echo ''",
                        returnStdout: true
                    ).trim()

                    if (!env.S3_PAYLOAD_KEY) {
                        error "âŒ No payload JSON found in bucket ${params.BUCKET}"
                    }

                    echo "âœ… Using payload: ${env.S3_PAYLOAD_KEY}"
                }
            }
        }

        stage('Download Payload') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    sh "aws s3 cp s3://${params.BUCKET}/${env.S3_PAYLOAD_KEY} payload.json"
                }
            }
        }

        stage('Parse Payload') {
            steps {
                script {
                    def payload = readJSON file: 'payload.json'
                    if (!payload.service_type) error "Missing service_type in payload"

                    env.SERVICE_TYPE = payload.service_type
                    echo """
                    ðŸ‘¤ User: ${payload.user_name}
                    ðŸ§© Service Type: ${env.SERVICE_TYPE}
                    ðŸ“¦ Client Email: ${payload.client_email}
                    """
                }
            }
        }

        stage('Terraform Init') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    script {
                        def payload = readJSON file: 'payload.json'
                        if (payload.service_type) {
                            sh "cp backends/backend-${payload.service_type}.tf backend.tf || echo 'No backend file for ${payload.service_type}'"
                            sh "terraform init -reconfigure -upgrade -input=false"
                        }
                    }
                }
            }
        }

        stage('Terraform Apply') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    script {
                        def payload = readJSON file: 'payload.json'
                        echo "ðŸš€ Applying Terraform for ${payload.service_type}"

                        sh """
                            terraform apply \
                              -var 's3_payload_bucket=${params.BUCKET}' \
                              -var 's3_payload_key=${env.S3_PAYLOAD_KEY}' \
                              -var 'aws_region=${AWS_DEFAULT_REGION}' \
                              -auto-approve
                        """

                        if (payload.service_type == 'ec2') {
                            sh """
                                terraform output -raw private_key_pem > client-access-key.pem
                                chmod 400 client-access-key.pem
                            """
                            archiveArtifacts artifacts: 'client-access-key.pem'
                        }
                    }
                }
            }
        }

        stage('Install Tools on EC2 (Ansible)') {
            when { expression { env.SERVICE_TYPE == 'ec2' } }
            steps {
                withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-terraform-creds']]) {
                    script {
                        def payload = readJSON file: 'payload.json'
                        def instance_name = payload.instances.keySet()[0]
                        def ip = sh(script: "terraform output -json ec2_public_ips | jq -r '.\"${instance_name}\"'", returnStdout: true).trim()

                        echo "ðŸ–¥ EC2 instance IP: ${ip}"

                        writeFile file: 'inventory.ini', text: """
                        [ec2]
                        ${ip} ansible_user=ubuntu ansible_ssh_private_key_file=client-access-key.pem
                        """

                        def tools = payload.instances[instance_name].tools_to_install ?: []
                        def tools_json = writeJSON returnText: true, json: tools

                        sh "ansible-playbook -i inventory.ini --extra-vars 'tools_to_install=${tools_json}' ansible/install_tools.yml"
                    }
                }
            }
        }

stage('Deploy Tools on EKS') {
  when { expression { env.SERVICE_TYPE == 'eks' } }
  steps {
    withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-terraform-creds']]) {
      script {
        def payload = readJSON file: 'payload.json'
        def cluster_name = payload.eks.cluster_name
        def region = env.AWS_DEFAULT_REGION ?: 'eu-central-1'
        def ecrBase = "430118831270.dkr.ecr.${region}.amazonaws.com"
        def useFargate = payload.eks.use_fargate == true

        echo "â˜¸ Deploying tools to EKS Cluster: ${cluster_name} (fargate=${useFargate})"

        // kubeconfig from Terraform
        def kubeconfig = sh(script: "terraform output -raw eks_kubeconfig", returnStdout: true).trim()
        writeFile file: 'kubeconfig.yaml', text: kubeconfig
        env.KUBECONFIG = "${WORKSPACE}/kubeconfig.yaml"

        // Login to ECR
        sh '''
          echo "ðŸ” Logging into ECR..."
          aws ecr get-login-password --region ''' + region + ''' | docker login --username AWS --password-stdin 430118831270.dkr.ecr.''' + region + '''.amazonaws.com
        '''

        // Helm repos (safe to call multiple times)
        sh '''
          helm repo add grafana https://grafana.github.io/helm-charts || true
          helm repo add prometheus https://prometheus-community.github.io/helm-charts || true
          helm repo update || true
          helm repo list || true
        '''

        // Ensure the target namespace(s) and create ecr pull secret
        sh "kubectl get ns monitoring >/dev/null 2>&1 || kubectl create ns monitoring"
        sh "kubectl delete secret ecr-creds -n monitoring --ignore-not-found || true"
        sh '''
          kubectl create secret docker-registry ecr-creds \
            --docker-server=''' + ecrBase + ''' \
            --docker-username=AWS \
            --docker-password="$(aws ecr get-login-password --region ''' + region + ''')" \
            --namespace monitoring
        '''
        sh "kubectl patch serviceaccount default -n monitoring -p '{\"imagePullSecrets\":[{\"name\":\"ecr-creds\"}]}' || true"

        // Collect fargate namespaces (if any) so we can validate
        def fargateNamespaces = (payload.eks.fargate_selectors ?: []).collect{ it.namespace ?: "" }

        def tools = payload.eks.tools_to_install ?: []
        if (!tools || tools.size() == 0) {
          echo "â„¹ï¸ No tools listed in payload.eks.tools_to_install â€” nothing to deploy."
        } else {
          tools.each { t ->
            def name = t.name ?: (t.tool ?: 'tool-'+UUID.randomUUID().toString()[0..7])
            def chart = t.chart ?: (t.chart_name ?: name)         // e.g. "grafana/grafana" or "grafana"
            def repo = t.chart_repo ?: t.repo ?: ''
            def namespace = t.namespace ?: 'default'
            def useEcr = (t.use_ecr instanceof Boolean) ? t.use_ecr : (t.use_ecr ?: false)
            def ecrUrl = t.ecr_repo_url ?: (useEcr ? "${ecrBase}/${name}" : '')
            def helm_overrides = t.helm_overrides ?: [:]

            echo "ðŸ“¦ Preparing install for ${name} (chart=${chart}, repo=${repo}, ns=${namespace}, useEcr=${useEcr})"

            // If Fargate is enabled, ensure the namespace is covered by a fargate selector
            if (useFargate && !fargateNamespaces.contains(namespace)) {
              error("Fargate enabled but namespace '${namespace}' is not listed in payload.eks.fargate_selectors. Add {\"namespace\":\"${namespace}\",\"labels\":{}} to payload or disable fargate for this cluster.")
            }

            // create namespace if missing
            sh "kubectl get ns ${namespace} >/dev/null 2>&1 || kubectl create ns ${namespace}"

            // Build values.yaml â€” we include multiple keys to cover common chart differences
            def values = new StringBuilder()
            values << "# Auto-generated values for ${name}\n"

            if (ecrUrl) {
              values << """
image:
  repository: "${ecrUrl}"
  tag: "latest"

imagePullSecrets:
  - name: ecr-creds

global:
  image:
    repository: "${ecrUrl}"
    tag: "latest"

server:
  image:
    repository: "${ecrUrl}"
    tag: "latest"

grafana:
  image:
    repository: "${ecrUrl}"
    tag: "latest"

prometheus:
  server:
    image:
      repository: "${ecrUrl}"
      tag: "latest"
"""
            } else {
              values << "# no ecrUrl provided â€” not overriding image repository\n"
            }

            // If prometheus-like chart OR override asks to disable the node exporter / daemonsets on Fargate:
            if (useFargate || (helm_overrides.disable_node_exporter == true)) {
              values << """
# Multiple possible keys to disable node-exporter / daemonsets (covers chart variants)
nodeExporter:
  enabled: false

prometheus-node-exporter:
  enabled: false

prometheusNodeExporter:
  enabled: false

kubeNodeScraper:
  enabled: false
"""
            }

            // If Fargate or user requested persistence disabled, disable PVCs (avoids (storage) scheduling edge cases on Fargate)
            if (useFargate || (helm_overrides.persistence_disabled == true) || (helm_overrides.persistentVolume_disabled == true) ) {
              values << """
# Disable persistence variants â€” different charts use different keys
persistence:
  enabled: false

server:
  persistentVolume:
    enabled: false

prometheus:
  server:
    persistentVolume:
      enabled: false

grafana:
  persistence:
    enabled: false

alertmanager:
  persistentVolume:
    enabled: false
"""
            }

            def valuesFile = "values-${name}.yaml"
            writeFile file: valuesFile, text: values.toString()
            echo "ðŸ”Ž values file for ${name} written -> ${valuesFile}"

            // Choose chart arg correctly:
            // - If repo is provided AND chart contains '/', pass chart name only and add --repo <repo>
            // - Else pass chart as-is (e.g. "grafana/grafana" if repo previously added to helm repo list)
            def chartArg = chart
            if (repo && chart.contains('/')) {
              chartArg = chart.tokenize('/').last() // e.g. "grafana" from "grafana/grafana"
            }

            def helmCmd = "helm upgrade --install ${name} ${chartArg}"
            if (repo && repo != '') { helmCmd += " --repo ${repo}" }
            helmCmd += " --namespace ${namespace} -f ${valuesFile} --wait --timeout 15m --debug"

            // Attempt helm up to 3 times
            def ok = false
            for (int attempt = 1; attempt <= 3; attempt++) {
              try {
                echo "âž¡ï¸ Helm attempt ${attempt} for ${name}: ${helmCmd}"
                sh helmCmd
                echo "âœ… Helm install succeeded for ${name}"
                ok = true
                break
              } catch (err) {
                echo "âš ï¸ Helm attempt ${attempt} failed for ${name}: ${err}"
                if (attempt < 3) {
                  echo "  will retry in 10s..."
                  sleep time: 10, unit: 'SECONDS'
                } else {
                  echo "âŒ Final failure for ${name} â€” collecting debug info"
                  sh "kubectl get all -n ${namespace} || true"
                  sh "kubectl get events -n ${namespace} --sort-by=.lastTimestamp | tail -n 50 || true"
                  error("Helm install failed for ${name} after 3 attempts")
                }
              }
            }
          } // end tools.each
        } // end if tools
        echo "âœ… Deploy stage finished for ${cluster_name}"
      } // end script
    } // end withCredentials
  } // end steps
} // end stage





        stage('Send Kubeconfig via Email') {
            when { expression { env.SERVICE_TYPE == 'eks' } }
            steps {
                script {
                    def payload = readJSON file: 'payload.json'
                    emailext(
                        to: payload.client_email,
                        subject: "EKS Cluster Access: ${payload.eks.cluster_name}",
                        body: """
Hello ${payload.user_name},

Your EKS cluster "${payload.eks.cluster_name}" is ready.

Save the attached kubeconfig file and run:
export KUBECONFIG=kubeconfig.yaml
kubectl get nodes

Regards,  
Samurai DevOps Team
                        """,
                        attachmentsPattern: 'kubeconfig.yaml',
                        mimeType: 'text/plain'
                    )
                }
            }
        }

        stage('Send EC2 SSH Credentials') {
            when { expression { env.SERVICE_TYPE == 'ec2' } }
            steps {
                script {
                    def payload = readJSON file: 'payload.json'
                    def instance_name = payload.instances.keySet()[0]
                    def ip = sh(script: "terraform output -json ec2_public_ips | jq -r '.\"${instance_name}\"'", returnStdout: true).trim()

                    emailext(
                        to: payload.client_email,
                        subject: "ðŸ”‘ SSH Access for Your EC2 Instance",
                        body: """
Hello ${payload.user_name},

Your EC2 instance is ready and reachable at:
ssh -i client-access-key.pem ubuntu@${ip}

Regards,  
Samurai DevOps Team
                        """,
                        attachmentsPattern: 'client-access-key.pem'
                    )
                }
            }
        }
    }

    post {
        always {
            sh 'rm -f client-access-key.pem payload.json kubeconfig.yaml inventory.ini || true'
        }
        success { echo "âœ… Pipeline completed successfully!" }
        failure { echo "âŒ Pipeline failed â€” check logs." }
    }
}

