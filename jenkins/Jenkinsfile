pipeline {
    agent any

    parameters {
        string(name: 'BUCKET', defaultValue: 'thesamuraibucket', description: 'S3 bucket name')
        string(name: 'KEY', defaultValue: '', description: 'Exact S3 object key (leave blank to auto-find latest)')
    }

    environment {
        AWS_DEFAULT_REGION = 'eu-central-1'
        TIMESTAMP = "${new Date().format('yyyyMMdd_HHmmss')}"
    }

    stages {

        stage('Checkout Repository') {
            steps {
                script {
                    checkout([$class: 'GitSCM',
                        branches: [[name: '*/main']],
                        userRemoteConfigs: [[url: 'https://github.com/NasriMohamedHedi/terraform-infra.git']]
                    ])
                }
            }
        }

        stage('Find Payload in S3') {
            steps {
                script {
                    env.S3_PAYLOAD_KEY = params.KEY ?: sh(
                        script: "aws s3 ls s3://${params.BUCKET}/ | sort | tail -n 1 | awk '{print \$4}' || echo ''",
                        returnStdout: true
                    ).trim()

                    if (!env.S3_PAYLOAD_KEY) {
                        error "‚ùå No payload JSON found in bucket ${params.BUCKET}"
                    }

                    echo "‚úÖ Using payload: ${env.S3_PAYLOAD_KEY}"
                }
            }
        }

        stage('Download Payload') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    sh "aws s3 cp s3://${params.BUCKET}/${env.S3_PAYLOAD_KEY} payload.json"
                }
            }
        }

        stage('Parse Payload') {
            steps {
                script {
                    def payload = readJSON file: 'payload.json'
                    if (!payload.service_type) error "Missing service_type in payload"

                    env.SERVICE_TYPE = payload.service_type
                    echo """
                    üë§ User: ${payload.user_name}
                    üß© Service Type: ${env.SERVICE_TYPE}
                    üì¶ Client Email: ${payload.client_email}
                    """
                }
            }
        }

        stage('Terraform Init') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    script {
                        def payload = readJSON file: 'payload.json'
                        if (payload.service_type) {
                            sh "cp backends/backend-${payload.service_type}.tf backend.tf || echo 'No backend file for ${payload.service_type}'"
                            sh "terraform init -reconfigure -upgrade -input=false"
                        }
                    }
                }
            }
        }

        stage('Terraform Apply') {
    steps {
        withCredentials([[ 
            $class: 'AmazonWebServicesCredentialsBinding',
            credentialsId: 'aws-terraform-creds',
            accessKeyVariable: 'AWS_ACCESS_KEY_ID',
            secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
        ]]) {
            script {
                def payload = readJSON file: 'payload.json'
                echo "üöÄ Applying Terraform for ${payload.service_type}"

                sh """
                    terraform apply \
                      -var 's3_payload_bucket=${params.BUCKET}' \
                      -var 's3_payload_key=${env.S3_PAYLOAD_KEY}' \
                      -var 'aws_region=${AWS_DEFAULT_REGION}' \
                      -auto-approve
                """

                if (payload.service_type == 'ec2') {
                    sh """
                        terraform output -raw private_key_pem > client-access-key.pem
                        chmod 400 client-access-key.pem
                    """
                    archiveArtifacts artifacts: 'client-access-key.pem'
                }
            }
        }
    }

    post {
  success {
    script {
      echo "üìê Terraform apply successful ‚Üí triggering diagram generation"

      build job: 'GenerateDiagram',
        wait: false,
        parameters: [
          string(
            name: 'S3_BUCKET',
            value: params.BUCKET
          ),
          string(
            name: 'S3_KEY',
            value: env.S3_PAYLOAD_KEY
          )
        ]
    }
  }
}
}

stage('Install Tools on EC2 (Ansible)') {
  when { expression { env.SERVICE_TYPE == 'ec2' } }
  steps {
    withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-terraform-creds']]) {
      script {
        def payload = readJSON file: 'payload.json'
        def instance_name = payload.instances.keySet()[0]
        def ip = sh(script: "terraform output -json ec2_public_ips | jq -r '.\"${instance_name}\"'", returnStdout: true).trim()

        echo "üñ• EC2 instance IP: ${ip}"

        // write inventory (unchanged)
        writeFile file: 'inventory.ini', text: """
[ec2]
${ip} ansible_user=ubuntu ansible_ssh_private_key_file=client-access-key.pem
"""

        def tools = payload.instances[instance_name].tools_to_install ?: []
        def tools_json = writeJSON returnText: true, json: tools

        // Ensure private key has correct permissions (should already be set earlier)
        sh "chmod 400 client-access-key.pem || true"

        // Create a local known_hosts file for this workspace and add the host key (non-interactive)
        sh """
          mkdir -p "${WORKSPACE}/.ssh"
          echo "‚è≥ Scanning host key for ${ip}..."
          ssh-keyscan -H ${ip} > ${WORKSPACE}/known_hosts 2>/dev/null || true
          echo "Known hosts file created at: ${WORKSPACE}/known_hosts"
        """

        // Optional quick connectivity test (helps debug failures)
        def ok = sh(script: "ssh -o BatchMode=yes -o ConnectTimeout=8 -o UserKnownHostsFile=${WORKSPACE}/known_hosts -i client-access-key.pem ubuntu@${ip} 'echo SSH_OK' || echo SSH_FAIL", returnStdout: true).trim()
        echo "SSH test result: ${ok}"

        if (ok != 'SSH_OK') {
          echo "‚ö†Ô∏è SSH connectivity test failed. Common causes:"
          echo "  ‚Ä¢ Instance not ready yet (EC2 cloud-init still running)."
          echo "  ‚Ä¢ Security group blocking port 22 from the Jenkins agent."
          echo "  ‚Ä¢ Wrong username/key (AMI expects another user)."
          // show netcat test (if available) to verify port 22 is open
          sh "echo 'Checking TCP port 22...' ; (nc -z -v ${ip} 22 && echo 'PORT_OPEN') || echo 'PORT_CLOSED' || true"
          // proceed anyway (ansible will show more logs), or uncomment the next line to fail early:
          // error('SSH test failed ‚Äî aborting Ansible run')
        }

        // Run ansible-playbook but instruct Ansible to use the workspace known_hosts file
        withEnv([
          "ANSIBLE_HOST_KEY_CHECKING=True",
          "ANSIBLE_SSH_COMMON_ARGS=-o UserKnownHostsFile=${WORKSPACE}/known_hosts -o StrictHostKeyChecking=yes"
        ]) {
          sh "ansible-playbook -i inventory.ini --extra-vars 'tools_to_install=${tools_json}' ansible/install_tools.yml"
        }
      }
    }
  }
}

stage('Deploy Tools on EKS') {
  when { expression { env.SERVICE_TYPE == 'eks' } }

  steps {
    withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-terraform-creds']]) {
      script {

        /* ===========================
           BASIC CONTEXT
        ============================ */
        def payload        = readJSON file: 'payload.json'
        def cluster_name   = payload.eks.cluster_name
        def region         = env.AWS_DEFAULT_REGION ?: 'eu-central-1'
        def ecrRegistry    = "430118831270.dkr.ecr.${region}.amazonaws.com"
        def HELM_BASE      = "${WORKSPACE}/helm"

        echo "‚ò∏ Deploying to EKS cluster: ${cluster_name}"

        /* ===========================
           KUBECONFIG
        ============================ */
        def kubeconfig = sh(
          script: "terraform output -raw eks_kubeconfig",
          returnStdout: true
        ).trim()

        writeFile file: 'kubeconfig.yaml', text: kubeconfig
        env.KUBECONFIG = "${WORKSPACE}/kubeconfig.yaml"

        /* ===========================
           ECR LOGIN
        ============================ */
        sh """
aws ecr get-login-password --region ${region} \
| docker login --username AWS --password-stdin ${ecrRegistry}
"""

        /* ===========================
           AWS LOAD BALANCER CONTROLLER
        ============================ */
        sh """
helm repo add eks https://aws.github.io/eks-charts || true
helm repo update || true

helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
  -n kube-system \
  --set clusterName=${cluster_name} \
  --set serviceAccount.create=true \
  --set region=${region} \
  --set v=2
"""

        /* ===========================
           MONITORING STACK
        ============================ */
        sh """
helm upgrade --install monitoring ${HELM_BASE}/monitoring \
  -n monitoring \
  --create-namespace \
  --timeout 15m
"""

        sh """
kubectl rollout status deployment/monitoring-grafana \
  -n monitoring --timeout=300s
"""

        /* ===========================
           NAMESPACES + ECR CREDS
        ============================ */
        def tools = payload.eks.tools_to_install ?: []

        if (tools.isEmpty()) {
          echo "‚ÑπÔ∏è No EKS tools to deploy"
          return
        }

        def namespaces = tools.collect { it.namespace ?: 'default' }.unique()

        namespaces.each { ns ->
          sh "kubectl get ns ${ns} >/dev/null 2>&1 || kubectl create ns ${ns}"

          sh "kubectl delete secret ecr-creds -n ${ns} --ignore-not-found || true"

          sh """
kubectl create secret docker-registry ecr-creds \
  --docker-server=${ecrRegistry} \
  --docker-username=AWS \
  --docker-password=\$(aws ecr get-login-password --region ${region}) \
  --namespace ${ns}
"""

          sh """
kubectl patch serviceaccount default -n ${ns} \
  -p '{\"imagePullSecrets\":[{\"name\":\"ecr-creds\"}]}' || true
"""
        }

        /* ===========================
           DEPLOY EACH TOOL
        ============================ */
        tools.each { t ->

          def name      = t.name
          def namespace = t.namespace ?: "default"
          def chart     = t.chart
          def tag       = t.image_tag ?: "latest"
          def ecrUrl    = t.ecr_repo_url ?: "${ecrRegistry}/${name}"

          echo "üì¶ Deploying tool: ${name}"

          def valuesFile = "values-${name}.yaml"
          writeFile file: valuesFile, text: """
image:
  repository: "${ecrUrl}"
  tag: "${tag}"

imagePullSecrets:
  - name: ecr-creds

serviceAccount:
  create: true
  imagePullSecrets:
    - name: ecr-creds
"""

          def chartPath = "${HELM_BASE}/${chart}"

          if (!fileExists(chartPath)) {
            error "‚ùå Helm chart not found: ${chartPath}"
          }

          retry(3) {
            sh """
helm upgrade --install ${name} ${chartPath} \
  -n ${namespace} \
  --create-namespace \
  -f ${valuesFile} \
  --timeout 20m
"""
          }

          sh """
kubectl rollout status deployment/${name} \
  -n ${namespace} --timeout=300s || true
"""
        }

        /* ===========================
           DASHBOARD URL
        ============================ */
        env.DASHBOARD_URL = "https://dashboard.${cluster_name}.thesamurai.com"
        echo "üåç Dashboard URL: ${env.DASHBOARD_URL}"

        echo "‚úÖ EKS deployment completed successfully"
      }
    }
  }
}



stage('Send EKS Dashboard Access') {
  when { expression { env.SERVICE_TYPE == 'eks' } }
  steps {
    script {
      def payload = readJSON file: 'payload.json'

      emailext(
        to: payload.client_email,
        subject: "üõ° Your EKS Security Dashboard is Ready",
        body: """
Hello ${payload.user_name},

Your EKS lab "${payload.eks.cluster_name}" is ready üöÄ

üîó Access your live dashboards here:
${env.DASHBOARD_URL}

What you can see:
‚Ä¢ Cluster health
‚Ä¢ Pods & namespaces
‚Ä¢ Security tools metrics
‚Ä¢ Real-time monitoring

No kubectl, no SSH required.

Regards,
Samurai DevOps Team
"""
      )
    }
  }
}

        stage('Send EC2 SSH Credentials') {
            when { expression { env.SERVICE_TYPE == 'ec2' } }
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    withEnv(["AWS_DEFAULT_REGION=eu-central-1"]) {
                        script {
                            def payload = readJSON file: 'payload.json'
                            def instance_name = payload.instances.keySet()[0]

                            // Terraform output now works because credentials are present
                            def ip = sh(
                                script: "terraform output -json ec2_public_ips | jq -r '.\"${instance_name}\"'",
                                returnStdout: true
                            ).trim()

                            emailext(
                                to: payload.client_email,
                                subject: "üîë SSH Access for Your EC2 Instance",
                                body: """
Hello ${payload.user_name},

Your EC2 instance is ready and reachable at:
ssh -i client-access-key.pem ubuntu@${ip}

Regards,  
Samurai DevOps Team
                                """,
                                attachmentsPattern: 'client-access-key.pem'
                            )
                        }
                    }
                }
            }
        }

    } // END stages

    post {
        always {
            sh 'rm -f client-access-key.pem payload.json kubeconfig.yaml inventory.ini || true'
        }
        success { echo "‚úÖ Pipeline completed successfully!" }
        failure { echo "‚ùå Pipeline failed ‚Äî check logs." }
    }

} // END pipeline
