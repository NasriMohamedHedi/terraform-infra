pipeline {
  agent any
  parameters {
    string(name: 'BUCKET', defaultValue: 'thesamuraibucket', description: 'S3 bucket name')
    string(name: 'KEY', defaultValue: '', description: 'Exact S3 object key (leave blank to auto-find latest)')
  }
  environment {
    AWS_DEFAULT_REGION = 'eu-central-1'
    JENKINS_URL = "${params.jenkins_url ?: 'https://9216d38c2a3f.ngrok-free.app'}"
    TIMESTAMP = "${new Date().format('yyyyMMdd_HHmmss')}"
  }
  stages {
    stage('Declarative: Checkout SCM') {
      steps {
        checkout scm
      }
    }
    stage('Checkout') {
      steps {
        git url: 'https://github.com/NasriMohamedHedi/terraform-infra.git', branch: 'main'
      }
    }
    stage('Find Payload JSON Key') {
      steps {
        script {
          env.S3_PAYLOAD_KEY = params.KEY ?: sh(script: "aws s3 ls s3://${params.BUCKET}/ | sort | tail -n 1 | awk '{print \$4}'", returnStdout: true).trim()
          echo "Using provided S3 key: ${env.S3_PAYLOAD_KEY}"
        }
      }
    }
    stage('Download Payload JSON') {
      steps {
        withCredentials([[
          $class: 'AmazonWebServicesCredentialsBinding',
          credentialsId: 'aws-terraform-creds',
          accessKeyVariable: 'AWS_ACCESS_KEY_ID',
          secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
        ]]) {
          sh "aws s3 cp s3://${params.BUCKET}/${env.S3_PAYLOAD_KEY} payload.json"
        }
      }
    }
    stage('Parse Payload for Service Type') {
      steps {
        script {
          def payload = readJSON file: 'payload.json'
          env.SERVICE_TYPE = payload.service_type
          echo "Payload JSON loaded:"
          echo "  User Name: ${payload.user_name}"
          echo "  Service Type: ${env.SERVICE_TYPE}"
          echo "  Instances: ${payload.instances.keySet() as List}"
        }
      }
    }
    stage('Terraform Init') {
      steps {
        withCredentials([[
          $class: 'AmazonWebServicesCredentialsBinding',
          credentialsId: 'aws-terraform-creds',
          accessKeyVariable: 'AWS_ACCESS_KEY_ID',
          secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
        ]]) {
          script {
            def payload = readJSON file: 'payload.json'
            sh "cp backends/backend-${env.SERVICE_TYPE}.tf backend.tf"
            sh "terraform init -input=false -reconfigure"
          }
        }
      }
    }
    stage('Terraform Apply') {
      steps {
        withCredentials([[
          $class: 'AmazonWebServicesCredentialsBinding',
          credentialsId: 'aws-terraform-creds',
          accessKeyVariable: 'AWS_ACCESS_KEY_ID',
          secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
        ]]) {
          script {
            def payload = readJSON file: 'payload.json'
            echo "Service Type detected: ${env.SERVICE_TYPE}"
            if (env.SERVICE_TYPE == 'ec2') {
              sh """
                terraform apply \
                  -var 's3_payload_bucket=${params.BUCKET}' \
                  -var 's3_payload_key=${env.S3_PAYLOAD_KEY}' \
                  -var 'jenkins_url=${JENKINS_URL}' \
                  -auto-approve
                terraform output -raw private_key_pem > client-access-key.pem
                chmod 400 client-access-key.pem
              """
            } else if (env.SERVICE_TYPE == 'eks') {
              sh """
                terraform apply \
                  -var 's3_payload_bucket=${params.BUCKET}' \
                  -var 's3_payload_key=${env.S3_PAYLOAD_KEY}' \
                  -auto-approve
              """
              def clusterName = sh(script: "terraform output -raw cluster_name", returnStdout: true).trim()
              echo "Cluster created: ${clusterName}"
              sh """
                aws eks update-kubeconfig --name ${clusterName} --region ${AWS_DEFAULT_REGION}
                echo "kubectl cluster-info"
                kubectl cluster-info || true
                kubectl get nodes --all-namespaces || true
              """
            } else {
              error("Invalid or unsupported service_type: ${env.SERVICE_TYPE}")
            }
          }
        }
      }
    }
    stage('Install Tools with Ansible') {
      when {
        expression { env.SERVICE_TYPE == 'ec2' }
      }
      steps {
        withCredentials([[
          $class: 'AmazonWebServicesCredentialsBinding',
          credentialsId: 'aws-terraform-creds',
          accessKeyVariable: 'AWS_ACCESS_KEY_ID',
          secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
        ]]) {
          script {
            def payload = readJSON file: 'payload.json'
            def instance_keys = payload.instances.keySet()
            def instance_key = instance_keys.iterator().next()
            def ip = sh(
              script: "terraform output -json ec2_public_ips | jq -r '.\"${instance_key}\"'",
              returnStdout: true
            ).trim()
            if (!ip) error("No IP found for instance ${instance_key}")
            def toolsList = payload.instances[instance_key].tools_to_install ?: []
            writeFile file: 'inventory.ini', text: "${ip} ansible_user=ubuntu ansible_ssh_private_key_file=${WORKSPACE}/client-access-key.pem"
            timeout(time: 20, unit: 'MINUTES') {
              retry(5) {
                sh """
                  until ssh -i client-access-key.pem -o StrictHostKeyChecking=no -o ConnectTimeout=10 ubuntu@${ip} 'echo SSH is up'; do
                    echo "Waiting for SSH..."
                    sleep 30
                  done
                """
              }
            }
            ansiblePlaybook(
              playbook: 'ansible/install_tools.yml',
              inventory: 'inventory.ini',
              extraVars: [
                tools_to_install: toolsList
              ]
            )
          }
        }
      }
    }
    stage('Send SSH Details') {
      when {
        expression { env.SERVICE_TYPE == 'ec2' }
      }
      steps {
        script {
          def payload = readJSON file: 'payload.json'
          def instance_keys = payload.instances.keySet()
          def instance_key = instance_keys.iterator().next()
          def ip = sh(script: "terraform output -json ec2_public_ips | jq -r '.\"${instance_key}\"'", returnStdout: true).trim()
          def privateKey = sh(script: "terraform output -raw private_key_pem", returnStdout: true).trim()
          def sshDetails = [
            ip: ip,
            user: 'ubuntu',
            privateKey: privateKey
          ]
          // Safely convert to JSON string without triggering toArray
          def jsonDetails = groovy.json.JsonOutput.toJson(sshDetails)
          sh "echo '${jsonDetails}' > ssh_details.json"
          withCredentials([[
            $class: 'AmazonWebServicesCredentialsBinding',
            credentialsId: 'aws-terraform-creds',
            accessKeyVariable: 'AWS_ACCESS_KEY_ID',
            secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
          ]]) {
            sh "aws s3 cp ssh_details.json s3://${params.BUCKET}/ssh_details_${env.TIMESTAMP}.json"
          }
        }
      }
    }
  }
  post {
    always {
      sh 'rm -f /tmp/client-access-key.pem outputs.json client-access-key.pem payload.json inventory.ini ssh_details.json || true'
    }
    success {
      echo "Pipeline completed successfully!"
    }
    failure {
      echo "Pipeline failed. Check logs for details."
    }
  }
}
