pipeline {
    agent any

    parameters {
        string(name: 'BUCKET', defaultValue: 'thesamuraibucket', description: 'S3 bucket name')
        string(name: 'KEY', defaultValue: '', description: 'Exact S3 object key (leave blank to auto-find latest)')
    }

    environment {
        AWS_DEFAULT_REGION = 'eu-central-1'
        TIMESTAMP = "${new Date().format('yyyyMMdd_HHmmss')}"
    }

    stages {

        stage('Checkout Repository') {
            steps {
                script {
                    checkout([$class: 'GitSCM',
                        branches: [[name: '*/main']],
                        userRemoteConfigs: [[url: 'https://github.com/NasriMohamedHedi/terraform-infra.git']]
                    ])
                }
            }
        }

        stage('Find Payload in S3') {
            steps {
                script {
                    env.S3_PAYLOAD_KEY = params.KEY ?: sh(
                        script: "aws s3 ls s3://${params.BUCKET}/ | sort | tail -n 1 | awk '{print \$4}' || echo ''",
                        returnStdout: true
                    ).trim()

                    if (!env.S3_PAYLOAD_KEY) {
                        error "‚ùå No payload JSON found in bucket ${params.BUCKET}"
                    }

                    echo "‚úÖ Using payload: ${env.S3_PAYLOAD_KEY}"
                }
            }
        }

        stage('Download Payload') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    sh "aws s3 cp s3://${params.BUCKET}/${env.S3_PAYLOAD_KEY} payload.json"
                }
            }
        }

        stage('Parse Payload') {
            steps {
                script {
                    def payload = readJSON file: 'payload.json'
                    if (!payload.service_type) error "Missing service_type in payload"

                    env.SERVICE_TYPE = payload.service_type
                    echo """
                    üë§ User: ${payload.user_name}
                    üß© Service Type: ${env.SERVICE_TYPE}
                    üì¶ Client Email: ${payload.client_email}
                    """
                }
            }
        }

        stage('Terraform Init') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    script {
                        def payload = readJSON file: 'payload.json'
                        if (payload.service_type) {
                            sh "cp backends/backend-${payload.service_type}.tf backend.tf || echo 'No backend file for ${payload.service_type}'"
                            sh "terraform init -reconfigure -upgrade -input=false"
                        }
                    }
                }
            }
        }

        stage('Terraform Apply') {
    steps {
        withCredentials([[ 
            $class: 'AmazonWebServicesCredentialsBinding',
            credentialsId: 'aws-terraform-creds',
            accessKeyVariable: 'AWS_ACCESS_KEY_ID',
            secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
        ]]) {
            script {
                def payload = readJSON file: 'payload.json'
                echo "üöÄ Applying Terraform for ${payload.service_type}"

                sh """
                    terraform apply \
                      -var 's3_payload_bucket=${params.BUCKET}' \
                      -var 's3_payload_key=${env.S3_PAYLOAD_KEY}' \
                      -var 'aws_region=${AWS_DEFAULT_REGION}' \
                      -auto-approve
                """

                if (payload.service_type == 'ec2') {
                    sh """
                        terraform output -raw private_key_pem > client-access-key.pem
                        chmod 400 client-access-key.pem
                    """
                    archiveArtifacts artifacts: 'client-access-key.pem'
                }
            }
        }
    }

    post {
  success {
    script {
      echo "üìê Terraform apply successful ‚Üí triggering diagram generation"

      build job: 'GenerateDiagram',
        wait: false,
        parameters: [
          string(
            name: 'S3_BUCKET',
            value: params.BUCKET
          ),
          string(
            name: 'S3_KEY',
            value: env.S3_PAYLOAD_KEY
          )
        ]
    }
  }
}
}

stage('Install Tools on EC2 (Ansible)') {
  when { expression { env.SERVICE_TYPE == 'ec2' } }
  steps {
    withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-terraform-creds']]) {
      script {
        def payload = readJSON file: 'payload.json'
        def instance_name = payload.instances.keySet()[0]
        def ip = sh(script: "terraform output -json ec2_public_ips | jq -r '.\"${instance_name}\"'", returnStdout: true).trim()

        echo "üñ• EC2 instance IP: ${ip}"

        // write inventory (unchanged)
        writeFile file: 'inventory.ini', text: """
[ec2]
${ip} ansible_user=ubuntu ansible_ssh_private_key_file=client-access-key.pem
"""

        def tools = payload.instances[instance_name].tools_to_install ?: []
        def tools_json = writeJSON returnText: true, json: tools

        // Ensure private key has correct permissions (should already be set earlier)
        sh "chmod 400 client-access-key.pem || true"

        // Create a local known_hosts file for this workspace and add the host key (non-interactive)
        sh """
          mkdir -p "${WORKSPACE}/.ssh"
          echo "‚è≥ Scanning host key for ${ip}..."
          ssh-keyscan -H ${ip} > ${WORKSPACE}/known_hosts 2>/dev/null || true
          echo "Known hosts file created at: ${WORKSPACE}/known_hosts"
        """

        // Optional quick connectivity test (helps debug failures)
        def ok = sh(script: "ssh -o BatchMode=yes -o ConnectTimeout=8 -o UserKnownHostsFile=${WORKSPACE}/known_hosts -i client-access-key.pem ubuntu@${ip} 'echo SSH_OK' || echo SSH_FAIL", returnStdout: true).trim()
        echo "SSH test result: ${ok}"

        if (ok != 'SSH_OK') {
          echo "‚ö†Ô∏è SSH connectivity test failed. Common causes:"
          echo "  ‚Ä¢ Instance not ready yet (EC2 cloud-init still running)."
          echo "  ‚Ä¢ Security group blocking port 22 from the Jenkins agent."
          echo "  ‚Ä¢ Wrong username/key (AMI expects another user)."
          // show netcat test (if available) to verify port 22 is open
          sh "echo 'Checking TCP port 22...' ; (nc -z -v ${ip} 22 && echo 'PORT_OPEN') || echo 'PORT_CLOSED' || true"
          // proceed anyway (ansible will show more logs), or uncomment the next line to fail early:
          // error('SSH test failed ‚Äî aborting Ansible run')
        }

        // Run ansible-playbook but instruct Ansible to use the workspace known_hosts file
        withEnv([
          "ANSIBLE_HOST_KEY_CHECKING=True",
          "ANSIBLE_SSH_COMMON_ARGS=-o UserKnownHostsFile=${WORKSPACE}/known_hosts -o StrictHostKeyChecking=yes"
        ]) {
          sh "ansible-playbook -i inventory.ini --extra-vars 'tools_to_install=${tools_json}' ansible/install_tools.yml"
        }
      }
    }
  }
}



stage('Deploy Tools on EKS') {
  when { expression { env.SERVICE_TYPE == 'eks' } }

  steps {
    withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-terraform-creds']]) {
      script {

        def payload     = readJSON file: 'payload.json'
        def clusterName = payload.eks.cluster_name
        def region      = env.AWS_DEFAULT_REGION ?: 'eu-central-1'
        def ecrRegistry = "430118831270.dkr.ecr.${region}.amazonaws.com"
        def HELM_BASE   = "${WORKSPACE}/helm"

        echo "‚ò∏ Deploying to EKS cluster: ${clusterName}"

        /* ================= KUBECONFIG ================= */
        writeFile file: 'kubeconfig.yaml',
          text: sh(script: "terraform output -raw eks_kubeconfig", returnStdout: true).trim()

        env.KUBECONFIG = "${WORKSPACE}/kubeconfig.yaml"

        /* ================= ECR LOGIN ================= */
        sh """
aws ecr get-login-password --region ${region} \
| docker login --username AWS --password-stdin ${ecrRegistry}
"""

        /* ================= ALB CONTROLLER ================= */
        sh """
helm repo add eks https://aws.github.io/eks-charts || true
helm repo update

helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
  -n kube-system \
  --create-namespace \
  --set clusterName=${clusterName} \
  --set serviceAccount.create=true \
  --set region=${region}
"""

        /* ================= KUBERNETES DASHBOARD ================= */
        sh """
helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/ || true
helm repo update

helm upgrade --install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard \
  -n kubernetes-dashboard \
  --create-namespace \
  --set protocolHttp=false \
  --set service.type=ClusterIP
"""

        sh """
kubectl rollout status deployment/kubernetes-dashboard \
  -n kubernetes-dashboard --timeout=300s
"""

        /* ================= ADMIN USER ================= */
        sh """
cat <<'YAML' > dashboard-adminuser.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard
YAML

kubectl apply -f dashboard-adminuser.yaml
"""

        /* ================= INSTALL YOUR MONITORING INGRESS ================= */
        sh """
helm upgrade --install monitoring ${HELM_BASE}/monitoring \
  -n kubernetes-dashboard \
  --timeout 10m
"""

        /* ================= ECR SECRET FOR TOOLS ================= */
        def tools = payload.eks.tools_to_install ?: []
        def namespaces = tools.collect { it.namespace ?: 'default' }.unique()

        namespaces.each { ns ->
          sh "kubectl get ns ${ns} || kubectl create ns ${ns}"

          sh """
kubectl delete secret ecr-creds -n ${ns} --ignore-not-found
kubectl create secret docker-registry ecr-creds \
  --docker-server=${ecrRegistry} \
  --docker-username=AWS \
  --docker-password=\$(aws ecr get-login-password --region ${region}) \
  -n ${ns}
"""
        }

        /* ================= DEPLOY CLIENT TOOLS ================= */
        tools.each { t ->

          def chartPath = "${HELM_BASE}/${t.chart}"

          if (!fileExists(chartPath)) {
            error "‚ùå Helm chart not found: ${chartPath}"
          }

          writeFile file: "values-${t.name}.yaml", text: """
image:
  repository: "${t.ecr_repo_url}"
  tag: "${t.image_tag}"
imagePullSecrets:
  - name: ecr-creds
"""

          sh """
helm upgrade --install ${t.name} ${chartPath} \
  -n ${t.namespace} \
  --create-namespace \
  -f values-${t.name}.yaml \
  --timeout 15m
"""
        }

        /* ================= GET ALB URL ================= */
        sleep 20

        def albHost = sh(
          script: """
kubectl get ingress eks-dashboard-ingress \
  -n kubernetes-dashboard \
  -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'
""",
          returnStdout: true
        ).trim()

        env.DASHBOARD_URL = "https://${albHost}"

        echo "üåç Dashboard URL: ${env.DASHBOARD_URL}"

        /* ================= GENERATE LOGIN TOKEN ================= */
        def token = sh(
          script: "kubectl -n kubernetes-dashboard create token admin-user",
          returnStdout: true
        ).trim()

        env.DASHBOARD_TOKEN = token

        echo "üîê Dashboard Token Generated"

        echo "‚úÖ EKS deployment completed successfully"
      }
    }
  }
}



stage('Send EKS Dashboard Access') {
  when { expression { env.SERVICE_TYPE == 'eks' } }
  steps {
    script {
      def payload = readJSON file: 'payload.json'

      emailext(
        to: payload.client_email,
        subject: "üõ° Your EKS Security Dashboard is Ready",
        body: """
Hello ${payload.user_name},

Your EKS lab "${payload.eks.cluster_name}" is ready üöÄ

üîó Access your live dashboards here:
${env.DASHBOARD_URL}

What you can see:
‚Ä¢ Cluster health
‚Ä¢ Pods & namespaces
‚Ä¢ Security tools metrics
‚Ä¢ Real-time monitoring

No kubectl, no SSH required.

Regards,
Samurai DevOps Team
"""
      )
    }
  }
}

        stage('Send EC2 SSH Credentials') {
            when { expression { env.SERVICE_TYPE == 'ec2' } }
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    withEnv(["AWS_DEFAULT_REGION=eu-central-1"]) {
                        script {
                            def payload = readJSON file: 'payload.json'
                            def instance_name = payload.instances.keySet()[0]

                            // Terraform output now works because credentials are present
                            def ip = sh(
                                script: "terraform output -json ec2_public_ips | jq -r '.\"${instance_name}\"'",
                                returnStdout: true
                            ).trim()

                            emailext(
                                to: payload.client_email,
                                subject: "üîë SSH Access for Your EC2 Instance",
                                body: """
Hello ${payload.user_name},

Your EC2 instance is ready and reachable at:
ssh -i client-access-key.pem ubuntu@${ip}

Regards,  
Samurai DevOps Team
                                """,
                                attachmentsPattern: 'client-access-key.pem'
                            )
                        }
                    }
                }
            }
        }

    } // END stages

    post {
        always {
            sh 'rm -f client-access-key.pem payload.json kubeconfig.yaml inventory.ini || true'
        }
        success { echo "‚úÖ Pipeline completed successfully!" }
        failure { echo "‚ùå Pipeline failed ‚Äî check logs." }
    }

} // END pipeline
