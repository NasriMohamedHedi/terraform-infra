pipeline {
    agent any

    parameters {
        string(name: 'BUCKET', defaultValue: 'thesamuraibucket', description: 'S3 bucket name')
        string(name: 'KEY', defaultValue: '', description: 'Exact S3 object key (leave blank to auto-find latest)')
    }

    environment {
        AWS_DEFAULT_REGION = 'eu-central-1'
        TIMESTAMP = "${new Date().format('yyyyMMdd_HHmmss')}"
    }

    stages {

        stage('Checkout Repository') {
            steps {
                script {
                    checkout([$class: 'GitSCM',
                        branches: [[name: '*/main']],
                        userRemoteConfigs: [[url: 'https://github.com/NasriMohamedHedi/terraform-infra.git']]
                    ])
                }
            }
        }

        stage('Find Payload in S3') {
            steps {
                script {
                    env.S3_PAYLOAD_KEY = params.KEY ?: sh(
                        script: "aws s3 ls s3://${params.BUCKET}/ | sort | tail -n 1 | awk '{print \$4}' || echo ''",
                        returnStdout: true
                    ).trim()

                    if (!env.S3_PAYLOAD_KEY) {
                        error "‚ùå No payload JSON found in bucket ${params.BUCKET}"
                    }

                    echo "‚úÖ Using payload: ${env.S3_PAYLOAD_KEY}"
                }
            }
        }

        stage('Download Payload') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    sh "aws s3 cp s3://${params.BUCKET}/${env.S3_PAYLOAD_KEY} payload.json"
                }
            }
        }

        stage('Parse Payload') {
            steps {
                script {
                    def payload = readJSON file: 'payload.json'
                    if (!payload.service_type) error "Missing service_type in payload"

                    env.SERVICE_TYPE = payload.service_type
                    echo """
                    üë§ User: ${payload.user_name}
                    üß© Service Type: ${env.SERVICE_TYPE}
                    üì¶ Client Email: ${payload.client_email}
                    """
                }
            }
        }

        stage('Terraform Init') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    script {
                        def payload = readJSON file: 'payload.json'
                        if (payload.service_type) {
                            sh "cp backends/backend-${payload.service_type}.tf backend.tf || echo 'No backend file for ${payload.service_type}'"
                            sh "terraform init -reconfigure -upgrade -input=false"
                        }
                    }
                }
            }
        }

        stage('Terraform Apply') {
    steps {
        withCredentials([[ 
            $class: 'AmazonWebServicesCredentialsBinding',
            credentialsId: 'aws-terraform-creds',
            accessKeyVariable: 'AWS_ACCESS_KEY_ID',
            secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
        ]]) {
            script {
                def payload = readJSON file: 'payload.json'
                echo "üöÄ Applying Terraform for ${payload.service_type}"

                sh """
                    terraform apply \
                      -var 's3_payload_bucket=${params.BUCKET}' \
                      -var 's3_payload_key=${env.S3_PAYLOAD_KEY}' \
                      -var 'aws_region=${AWS_DEFAULT_REGION}' \
                      -auto-approve
                """

                if (payload.service_type == 'ec2') {
                    sh """
                        terraform output -raw private_key_pem > client-access-key.pem
                        chmod 400 client-access-key.pem
                    """
                    archiveArtifacts artifacts: 'client-access-key.pem'
                }
            }
        }
    }

    post {
  success {
    script {
      echo "üìê Terraform apply successful ‚Üí triggering diagram generation"

      build job: 'GenerateDiagram',
        wait: false,
        parameters: [
          string(
            name: 'S3_BUCKET',
            value: params.BUCKET
          ),
          string(
            name: 'S3_KEY',
            value: env.S3_PAYLOAD_KEY
          )
        ]
    }
  }
}
}

stage('Install Tools on EC2 (Ansible)') {
  when { expression { env.SERVICE_TYPE == 'ec2' } }
  steps {
    withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-terraform-creds']]) {
      script {
        def payload = readJSON file: 'payload.json'
        def instance_name = payload.instances.keySet()[0]
        def ip = sh(script: "terraform output -json ec2_public_ips | jq -r '.\"${instance_name}\"'", returnStdout: true).trim()

        echo "üñ• EC2 instance IP: ${ip}"

        // write inventory (unchanged)
        writeFile file: 'inventory.ini', text: """
[ec2]
${ip} ansible_user=ubuntu ansible_ssh_private_key_file=client-access-key.pem
"""

        def tools = payload.instances[instance_name].tools_to_install ?: []
        def tools_json = writeJSON returnText: true, json: tools

        // Ensure private key has correct permissions (should already be set earlier)
        sh "chmod 400 client-access-key.pem || true"

        // Create a local known_hosts file for this workspace and add the host key (non-interactive)
        sh """
          mkdir -p "${WORKSPACE}/.ssh"
          echo "‚è≥ Scanning host key for ${ip}..."
          ssh-keyscan -H ${ip} > ${WORKSPACE}/known_hosts 2>/dev/null || true
          echo "Known hosts file created at: ${WORKSPACE}/known_hosts"
        """

        // Optional quick connectivity test (helps debug failures)
        def ok = sh(script: "ssh -o BatchMode=yes -o ConnectTimeout=8 -o UserKnownHostsFile=${WORKSPACE}/known_hosts -i client-access-key.pem ubuntu@${ip} 'echo SSH_OK' || echo SSH_FAIL", returnStdout: true).trim()
        echo "SSH test result: ${ok}"

        if (ok != 'SSH_OK') {
          echo "‚ö†Ô∏è SSH connectivity test failed. Common causes:"
          echo "  ‚Ä¢ Instance not ready yet (EC2 cloud-init still running)."
          echo "  ‚Ä¢ Security group blocking port 22 from the Jenkins agent."
          echo "  ‚Ä¢ Wrong username/key (AMI expects another user)."
          // show netcat test (if available) to verify port 22 is open
          sh "echo 'Checking TCP port 22...' ; (nc -z -v ${ip} 22 && echo 'PORT_OPEN') || echo 'PORT_CLOSED' || true"
          // proceed anyway (ansible will show more logs), or uncomment the next line to fail early:
          // error('SSH test failed ‚Äî aborting Ansible run')
        }

        // Run ansible-playbook but instruct Ansible to use the workspace known_hosts file
        withEnv([
          "ANSIBLE_HOST_KEY_CHECKING=True",
          "ANSIBLE_SSH_COMMON_ARGS=-o UserKnownHostsFile=${WORKSPACE}/known_hosts -o StrictHostKeyChecking=yes"
        ]) {
          sh "ansible-playbook -i inventory.ini --extra-vars 'tools_to_install=${tools_json}' ansible/install_tools.yml"
        }
      }
    }
  }
}



stage('Deploy Tools on EKS') {
  when { expression { env.SERVICE_TYPE == 'eks' } }
  steps {
    withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-terraform-creds']]) {
      script {
        def payload      = readJSON file: 'payload.json'
        def cluster_name = payload.eks.cluster_name
        def region       = env.AWS_DEFAULT_REGION ?: 'eu-central-1'
        def ecrRegistry  = "430118831270.dkr.ecr.${region}.amazonaws.com"
        def HELM_BASE    = "${WORKSPACE}/helm"
        // Pick a dashboard version to install; update if you want a newer one
        def DASHBOARD_VERSION = "v2.8.0"
        def DASHBOARD_MANIFEST = "https://raw.githubusercontent.com/kubernetes/dashboard/${DASHBOARD_VERSION}/aio/deploy/recommended.yaml"

        echo "‚ò∏ Deploying to EKS cluster: ${cluster_name}"

        // kubeconfig from terraform
        def kubeconfig = sh(script: "terraform output -raw eks_kubeconfig", returnStdout: true).trim()
        writeFile file: 'kubeconfig.yaml', text: kubeconfig
        env.KUBECONFIG = "${WORKSPACE}/kubeconfig.yaml"

        // login to ECR
        sh """
aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin ${ecrRegistry}
"""

        // ensure load-balancer controller ‚Äì (safe idempotent install)
        sh """
helm repo add eks https://aws.github.io/eks-charts || true
helm repo update || true

helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \\
  -n kube-system \\
  --create-namespace \\
  --set clusterName=${cluster_name} \\
  --set serviceAccount.create=true \\
  --set region=${region} \\
  --set v=2
"""

        // -----------------------------
        // Install Kubernetes Dashboard
        // -----------------------------
        // apply official recommended manifest
        sh """
echo "Applying Kubernetes Dashboard recommended manifest (${DASHBOARD_VERSION})..."
kubectl apply -f ${DASHBOARD_MANIFEST}
"""

        // create admin-user ServiceAccount + ClusterRoleBinding (safe idempotent apply)
        sh """
cat <<'YAML' > dashboard-adminuser.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard
YAML

kubectl apply -f dashboard-adminuser.yaml
"""

        // create ALB Ingress that points to kubernetes-dashboard service (listens HTTPS -> backend HTTPS)
        def ingressHost = "dashboard.${cluster_name}.thesamurai.com"
        sh """
cat <<'YAML' > kubernetes-dashboard-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: kubernetes-dashboard-ingress
  namespace: kubernetes-dashboard
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/backend-protocol: HTTPS
    # listen on 443 (HTTPS) on the ALB
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS":443}]'
spec:
  rules:
  - host: ${ingressHost}
    http:
      paths:
      - path: /
        pathType: ImplementationSpecific
        backend:
          service:
            name: kubernetes-dashboard
            port:
              number: 443
YAML

kubectl apply -f kubernetes-dashboard-ingress.yaml
"""

        // Wait for the ingress (ALB) to get an hostname. We'll poll for up to ~6 minutes
        echo "Waiting for ALB hostname..."
        def albHost = ""
        for (int i = 0; i < 36; i++) { // 36 * 10s = 6 minutes
          albHost = sh(script: "kubectl -n kubernetes-dashboard get ingress kubernetes-dashboard-ingress -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || true", returnStdout: true).trim()
          if (albHost) {
            echo "ALB hostname: ${albHost}"
            break
          }
          echo "  waiting 10s for ALB to provision..."
          sleep time: 10, unit: 'SECONDS'
        }
        if (!albHost?.trim()) {
          error("ALB did not become ready in time ‚Äî check aws-load-balancer-controller logs and the Ingress resource.")
        }

        // Build dashboard URL (https)
        env.DASHBOARD_URL = "https://${albHost}"
        echo "Dashboard external URL: ${env.DASHBOARD_URL}"

        // Try to obtain a token for admin-user in a robust way:
        // prefer `kubectl -n kubernetes-dashboard create token admin-user` (K8s >=1.24),
        // fallback to extracting secret and base64-decoding it.
        def dashboardToken = ""
        try {
          dashboardToken = sh(script: "kubectl -n kubernetes-dashboard create token admin-user 2>/dev/null || true", returnStdout: true).trim()
        } catch (e) {
          dashboardToken = ""
        }
        if (!dashboardToken) {
          // fallback extraction
          dashboardToken = sh(script: "kubectl -n kubernetes-dashboard get sa admin-user -o jsonpath='{.secrets[0].name}' | xargs -I{} kubectl -n kubernetes-dashboard get secret {} -o jsonpath='{.data.token}' | base64 --decode", returnStdout: true).trim()
        }
        if (!dashboardToken) {
          echo "‚ö†Ô∏è Could not extract dashboard token automatically. You may need to inspect the secret manually."
        } else {
          // mask the token in build logs output where possible
          env.DASHBOARD_TOKEN = dashboardToken
          echo "‚úÖ Dashboard token generated (masked in logs)."
        }

        // Optionally: write token to a file so that subsequent email stage can attach it
        writeFile file: 'dashboard_token.txt', text: env.DASHBOARD_TOKEN ?: "<token-unavailable>"

        echo "‚úÖ EKS dashboard and ingress deployed. Dashboard URL: ${env.DASHBOARD_URL}"
      }
    }
  }
}




stage('Send EKS Dashboard Access') {
  when { expression { env.SERVICE_TYPE == 'eks' } }
  steps {
    script {
      def payload = readJSON file: 'payload.json'

      emailext(
        to: payload.client_email,
        subject: "üõ° Your EKS Security Dashboard is Ready",
        body: """
Hello ${payload.user_name},

Your EKS lab "${payload.eks.cluster_name}" is ready üöÄ

üîó Access your live dashboards here:
${env.DASHBOARD_URL}

What you can see:
‚Ä¢ Cluster health
‚Ä¢ Pods & namespaces
‚Ä¢ Security tools metrics
‚Ä¢ Real-time monitoring

No kubectl, no SSH required.

Regards,
Samurai DevOps Team
"""
      )
    }
  }
}

        stage('Send EC2 SSH Credentials') {
            when { expression { env.SERVICE_TYPE == 'ec2' } }
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    withEnv(["AWS_DEFAULT_REGION=eu-central-1"]) {
                        script {
                            def payload = readJSON file: 'payload.json'
                            def instance_name = payload.instances.keySet()[0]

                            // Terraform output now works because credentials are present
                            def ip = sh(
                                script: "terraform output -json ec2_public_ips | jq -r '.\"${instance_name}\"'",
                                returnStdout: true
                            ).trim()

                            emailext(
                                to: payload.client_email,
                                subject: "üîë SSH Access for Your EC2 Instance",
                                body: """
Hello ${payload.user_name},

Your EC2 instance is ready and reachable at:
ssh -i client-access-key.pem ubuntu@${ip}

Regards,  
Samurai DevOps Team
                                """,
                                attachmentsPattern: 'client-access-key.pem'
                            )
                        }
                    }
                }
            }
        }

    } // END stages

    post {
        always {
            sh 'rm -f client-access-key.pem payload.json kubeconfig.yaml inventory.ini || true'
        }
        success { echo "‚úÖ Pipeline completed successfully!" }
        failure { echo "‚ùå Pipeline failed ‚Äî check logs." }
    }

} // END pipeline
