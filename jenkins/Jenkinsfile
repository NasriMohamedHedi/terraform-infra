pipeline {
    agent any

    parameters {
        string(name: 'BUCKET', defaultValue: 'thesamuraibucket', description: 'S3 bucket name')
        string(name: 'KEY', defaultValue: '', description: 'Exact S3 object key (leave blank to auto-find latest)')
    }

    environment {
        AWS_DEFAULT_REGION = 'eu-central-1'
        TIMESTAMP = "${new Date().format('yyyyMMdd_HHmmss')}"
    }

    stages {

        stage('Checkout Repository') {
            steps {
                script {
                    checkout([$class: 'GitSCM',
                        branches: [[name: '*/main']],
                        userRemoteConfigs: [[url: 'https://github.com/NasriMohamedHedi/terraform-infra.git']]
                    ])
                }
            }
        }

        stage('Find Payload in S3') {
            steps {
                script {
                    env.S3_PAYLOAD_KEY = params.KEY ?: sh(
                        script: "aws s3 ls s3://${params.BUCKET}/ | sort | tail -n 1 | awk '{print \$4}' || echo ''",
                        returnStdout: true
                    ).trim()

                    if (!env.S3_PAYLOAD_KEY) {
                        error "âŒ No payload JSON found in bucket ${params.BUCKET}"
                    }

                    echo "âœ… Using payload: ${env.S3_PAYLOAD_KEY}"
                }
            }
        }

        stage('Download Payload') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    sh "aws s3 cp s3://${params.BUCKET}/${env.S3_PAYLOAD_KEY} payload.json"
                }
            }
        }

        stage('Parse Payload') {
            steps {
                script {
                    def payload = readJSON file: 'payload.json'
                    if (!payload.service_type) error "Missing service_type in payload"

                    env.SERVICE_TYPE = payload.service_type
                    echo """
                    ðŸ‘¤ User: ${payload.user_name}
                    ðŸ§© Service Type: ${env.SERVICE_TYPE}
                    ðŸ“¦ Client Email: ${payload.client_email}
                    """
                }
            }
        }

        stage('Terraform Init') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    script {
                        def payload = readJSON file: 'payload.json'
                        if (payload.service_type) {
                            sh "cp backends/backend-${payload.service_type}.tf backend.tf || echo 'No backend file for ${payload.service_type}'"
                            sh "terraform init -reconfigure -upgrade -input=false"
                        }
                    }
                }
            }
        }

        stage('Terraform Apply') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-terraform-creds',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    script {
                        def payload = readJSON file: 'payload.json'
                        echo "ðŸš€ Applying Terraform for ${payload.service_type}"

                        sh """
                            terraform apply \
                              -var 's3_payload_bucket=${params.BUCKET}' \
                              -var 's3_payload_key=${env.S3_PAYLOAD_KEY}' \
                              -var 'aws_region=${AWS_DEFAULT_REGION}' \
                              -auto-approve
                        """

                        if (payload.service_type == 'ec2') {
                            sh """
                                terraform output -raw private_key_pem > client-access-key.pem
                                chmod 400 client-access-key.pem
                            """
                            archiveArtifacts artifacts: 'client-access-key.pem'
                        }
                    }
                }
            }
        }

        stage('Install Tools on EC2 (Ansible)') {
            when { expression { env.SERVICE_TYPE == 'ec2' } }
            steps {
                withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-terraform-creds']]) {
                    script {
                        def payload = readJSON file: 'payload.json'
                        def instance_name = payload.instances.keySet()[0]
                        def ip = sh(script: "terraform output -json ec2_public_ips | jq -r '.\"${instance_name}\"'", returnStdout: true).trim()

                        echo "ðŸ–¥ EC2 instance IP: ${ip}"

                        writeFile file: 'inventory.ini', text: """
                        [ec2]
                        ${ip} ansible_user=ubuntu ansible_ssh_private_key_file=client-access-key.pem
                        """

                        def tools = payload.instances[instance_name].tools_to_install ?: []
                        def tools_json = writeJSON returnText: true, json: tools

                        sh "ansible-playbook -i inventory.ini --extra-vars 'tools_to_install=${tools_json}' ansible/install_tools.yml"
                    }
                }
            }
        }
stage('Deploy Tools on EKS') {
  when { expression { env.SERVICE_TYPE == 'eks' } }
  steps {
    withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-terraform-creds']]) {
      script {
        def payload = readJSON file: 'payload.json'
        def cluster_name = payload.eks.cluster_name
        def region = env.AWS_DEFAULT_REGION ?: 'eu-central-1'
        // prefer explicit ecr_repo_url from payload tool; fallback base
        def ecrBase = "430118831270.dkr.ecr.${region}.amazonaws.com"
        def useFargate = payload.eks.use_fargate == true

        echo "â˜¸ Deploying tools to EKS Cluster: ${cluster_name} (fargate=${useFargate})"

        // fetch kubeconfig from terraform outputs and set KUBECONFIG
        def kubeconfig = sh(script: "terraform output -raw eks_kubeconfig", returnStdout: true).trim()
        writeFile file: 'kubeconfig.yaml', text: kubeconfig
        env.KUBECONFIG = "${WORKSPACE}/kubeconfig.yaml"

        // docker login for ECR (for helm charts using local tar, not always needed but safe)
        sh """
          echo "ðŸ” Logging into ECR..."
          aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin ${ecrBase}
        """

        // add repos once (idempotent)
        sh '''
          helm repo add grafana https://grafana.github.io/helm-charts || true
          helm repo add prometheus https://prometheus-community.github.io/helm-charts || true
          helm repo update || true
          helm repo list || true
        '''

        // collect namespaces required by tools (default -> 'default')
        def tools = payload.eks.tools_to_install ?: []
        def namespaces = (tools.collect { it.namespace ?: 'default' } + ['monitoring']).unique()

        // create namespaces and create ecr-creds secret in each
        namespaces.each { ns ->
          sh "kubectl get ns ${ns} >/dev/null 2>&1 || kubectl create ns ${ns}"

          // recreate secret to ensure valid token
          sh "kubectl delete secret ecr-creds -n ${ns} --ignore-not-found || true"

          // Build the kubectl create secret command by concatenation to avoid Groovy string/dollar parsing issues
          def createSecretCmd = "kubectl create secret docker-registry ecr-creds " +
                                "--docker-server='${ecrBase}' " +
                                "--docker-username=AWS " +
                                "--docker-password=\"\$(aws ecr get-login-password --region ${region})\" " +
                                "--namespace ${ns}"
          sh createSecretCmd

          // patch default serviceaccount so pods using default SA will be able to pull images
          sh "kubectl patch serviceaccount default -n ${ns} -p '{\"imagePullSecrets\":[{\"name\":\"ecr-creds\"}]}' || true"
        }

        if (!tools || tools.size() == 0) {
          echo "â„¹ï¸ No tools listed in payload.eks.tools_to_install â€” nothing to deploy."
        } else {
          tools.each { t ->
            def name = t.name ?: (t.tool ?: 'tool-'+UUID.randomUUID().toString()[0..7])
            def chart = t.chart ?: (t.chart_name ?: name)         // e.g. "grafana/grafana" or "grafana"
            def repo = t.chart_repo ?: t.repo ?: ''
            def namespace = t.namespace ?: 'default'
            def useEcr = (t.use_ecr instanceof Boolean) ? t.use_ecr : (t.use_ecr ?: false)
            def ecrUrl = t.ecr_repo_url ?: (useEcr ? "${ecrBase}/${name}" : '')
            def tag = t.image_tag ?: 'latest'
            def helm_overrides = t.helm_overrides ?: [:]

            echo "ðŸ“¦ Preparing install for ${name} (chart=${chart}, repo=${repo}, ns=${namespace}, useEcr=${useEcr}, image=${ecrUrl}:${tag})"

            // Validate fargate namespace coverage (prevent scheduling issues)
            def fargateNamespaces = (payload.eks.fargate_selectors ?: []).collect{ it.namespace ?: "" }
            if (useFargate && !fargateNamespaces.contains(namespace)) {
              error("Fargate enabled but namespace '${namespace}' is not listed in payload.eks.fargate_selectors. Add {\"namespace\":\"${namespace}\",\"labels\":{}} to payload or disable fargate for this cluster.")
            }

            // Build a values file that: sets image repository/tag, sets imagePullSecrets, disables persistence/node-exporter, and ensures the ServiceAccount references the secret
            def values = new StringBuilder()
            values << "# Auto-generated values for ${name}\n"

            if (ecrUrl) {
              values << """
image:
  repository: "${ecrUrl}"
  tag: "${tag}"

imagePullSecrets:
  - name: ecr-creds

global:
  image:
    repository: "${ecrUrl}"
    tag: "${tag}"
"""
            } else {
              values << "# no ecrUrl provided â€” not overriding image repository\n"
            }

            // persistence disable (cover common chart keys)
            values << """
persistence:
  enabled: false

server:
  persistentVolume:
    enabled: false

grafana:
  persistence:
    enabled: false

prometheus:
  server:
    persistentVolume:
      enabled: false

alertmanager:
  persistentVolume:
    enabled: false
"""

            // node-exporter / daemonset disable for Fargate
            if (useFargate || (helm_overrides.disable_node_exporter == true)) {
              values << """
nodeExporter:
  enabled: false

prometheus-node-exporter:
  enabled: false

prometheusNodeExporter:
  enabled: false

kubeNodeScraper:
  enabled: false
"""
            }

            // ensure serviceAccount uses imagePullSecrets (many charts support serviceAccount.imagePullSecrets)
            values << """
serviceAccount:
  create: true
  imagePullSecrets:
    - name: ecr-creds
"""

            // apply any user-provided helm_overrides (merged)
            if (helm_overrides && helm_overrides.size() > 0) {
              def overridesYaml = groovy.json.JsonOutput.toJson(helm_overrides)
              // append as a yaml block (best-effort)
              values << "\n# user helm_overrides (json): ${overridesYaml}\n"
            }

            def valuesFile = "values-${name}.yaml"
            writeFile file: valuesFile, text: values.toString()
            echo "ðŸ”Ž values file for ${name} written -> ${valuesFile}"

            // Chart arg handling: if repo provided and chart contains '/', pass chart name; else pass chart as-is
            def chartArg = chart
            if (repo && chart.contains('/')) {
              chartArg = chart.tokenize('/').last()
            }

            // Build base helm command and add --set image.repository/tag to cover charts that require set-overrides
            def helmCmd = "helm upgrade --install ${name} ${chartArg}"
            if (repo && repo != '') { helmCmd += " --repo ${repo}" }
            helmCmd += " --namespace ${namespace} -f ${valuesFile} --wait --timeout 30m --debug"
            // also add set values to increase compatibility
            if (ecrUrl) {
              helmCmd += " --set image.repository=${ecrUrl} --set image.tag=${tag} --set global.image.repository=${ecrUrl} --set global.image.tag=${tag}"
            }

            // attempt helm up to 3 times with post-failure debug collection
            def ok = false
            for (int attempt = 1; attempt <= 3; attempt++) {
              try {
                echo "âž¡ï¸ Helm attempt ${attempt} for ${name}: ${helmCmd}"
                sh helmCmd
                echo "âœ… Helm install succeeded for ${name}"

                // After install, patch the release serviceaccount name to reference ecr-creds as fallback
                // Many charts create a serviceaccount with the release name; try patching it
                sh "kubectl patch serviceaccount ${name} -n ${namespace} -p '{\"imagePullSecrets\":[{\"name\":\"ecr-creds\"}]}' || true"

                // Wait for Deployment(s) rollout (best-effort)
                // list deployments in namespace matching release name prefix
                sh """
                  for d in \$(kubectl get deploy -n ${namespace} -o name | grep ${name} || true); do
                    echo "waiting rollout status for \$d"
                    kubectl rollout status \$d -n ${namespace} --timeout=300s || true
                  done
                """
                ok = true
                break
              } catch (err) {
                echo "âš ï¸ Helm attempt ${attempt} failed for ${name}: ${err}"
                // collect debug info
                sh "kubectl get all -n ${namespace} || true"
                sh "echo '=== Describe pods ==='; kubectl describe pods -n ${namespace} | sed -n '1,200p' || true"
                sh "echo '=== Recent events ==='; kubectl get events -n ${namespace} --sort-by=.lastTimestamp | tail -n 50 || true"
                sh "echo '=== Pod logs (last 200 lines) ==='; for p in \$(kubectl get pods -n ${namespace} -o name | sed 's#pod/##'); do echo '---- logs for' \$p; kubectl logs \$p -n ${namespace} --tail=200 || true; done || true"

                if (attempt < 3) {
                  echo "  will retry in 10s..."
                  sleep time: 10, unit: 'SECONDS'
                } else {
                  error("Helm install failed for ${name} after 3 attempts")
                }
              }
            } // end attempts
          } // end tools.each
        } // end if tools
        echo "âœ… Deploy stage finished for ${cluster_name}"
      } // end script
    } // end withCredentials
  } // end steps
} // end stage




        stage('Send Kubeconfig via Email') {
            when { expression { env.SERVICE_TYPE == 'eks' } }
            steps {
                script {
                    def payload = readJSON file: 'payload.json'
                    emailext(
                        to: payload.client_email,
                        subject: "EKS Cluster Access: ${payload.eks.cluster_name}",
                        body: """
Hello ${payload.user_name},

Your EKS cluster "${payload.eks.cluster_name}" is ready.

Save the attached kubeconfig file and run:
export KUBECONFIG=kubeconfig.yaml
kubectl get nodes

Regards,  
Samurai DevOps Team
                        """,
                        attachmentsPattern: 'kubeconfig.yaml',
                        mimeType: 'text/plain'
                    )
                }
            }
        }

        stage('Send EC2 SSH Credentials') {
            when { expression { env.SERVICE_TYPE == 'ec2' } }
            steps {
                script {
                    def payload = readJSON file: 'payload.json'
                    def instance_name = payload.instances.keySet()[0]
                    def ip = sh(script: "terraform output -json ec2_public_ips | jq -r '.\"${instance_name}\"'", returnStdout: true).trim()

                    emailext(
                        to: payload.client_email,
                        subject: "ðŸ”‘ SSH Access for Your EC2 Instance",
                        body: """
Hello ${payload.user_name},

Your EC2 instance is ready and reachable at:
ssh -i client-access-key.pem ubuntu@${ip}

Regards,  
Samurai DevOps Team
                        """,
                        attachmentsPattern: 'client-access-key.pem'
                    )
                }
            }
        }
    }

    post {
        always {
            sh 'rm -f client-access-key.pem payload.json kubeconfig.yaml inventory.ini || true'
        }
        success { echo "âœ… Pipeline completed successfully!" }
        failure { echo "âŒ Pipeline failed â€” check logs." }
    }
}

